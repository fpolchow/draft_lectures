{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias: the difference between an estimator's expected value and the true value of the parameter being estimate\n",
    "\n",
    "#### Variance: the variability of a model prediction for a given data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ MSE(X) = E[(Y - \\hat{f}(x))^2]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $MSE(x) = (E[\\hat{f}(x)] - f(x))^2 + E[(\\hat{f}(x)-E[\\hat{f}(x)])^2] + \\sigma_{e}^2$\n",
    "\n",
    "$ MSE(x) = Bias^2 + Variance + Irreducible\\ Error $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underfitting: When our model is unable to detect the \"signal\" present in our data.\n",
    "\n",
    "Overfitting: When our model is fit to the \"noise\" of our data rather than the \"signal.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./resources/overfit_underfit.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"./resources/Bias-Variance Tradeoff.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to deal with a model that is overfit to data:\n",
    "\n",
    "* Train with more data\n",
    "* Feature Subset Selection\n",
    "* Cross Validation\n",
    "* Regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature subset selection:\n",
    "* Forward step selection\n",
    "* Backward step selection\n",
    "* Forward-backward step selection\n",
    "\n",
    "\n",
    "http://www.biostat.jhsph.edu/~iruczins/teaching/jf/ch10.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "<img src=\"./resources/train_test_split.png\">\n",
    "#### Steps to cross validation\n",
    "1. Split your data into training and validation sets.\n",
    "2. Train models of varying complexity on the training set.\n",
    "3. Make predictions with the validation set.\n",
    "4. Choose the model that performs best on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold cross validation\n",
    "\n",
    "1. Split the data into k # of folds.\n",
    "2. Train your model on k-1 of the folds\n",
    "3. Test on the remaining fold.\n",
    "4. Repeat k times, and find the average score for whichever metric you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Regularization\n",
    "\n",
    "\n",
    "Reduce the effect that each parameter has on a predictive model. We will dive more into this soon.\n",
    "\n",
    "<img src = \"./resources/lasso_ridge.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "http://scott.fortmann-roe.com/docs/BiasVariance.html\n",
    "\n",
    "https://www.youtube.com/watch?v=jiQamxz2ZcQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
